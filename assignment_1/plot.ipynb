{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbpresent": {
     "id": "c6dfb14d-2def-4705-9667-b127d73f1150"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbpresent": {
     "id": "e70d7fcb-29bb-4162-a9b0-131d038cab37"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate : 0.0001\n",
      "max_steps : 8000\n",
      "batch_size : 64\n",
      "eval_freq : 500\n",
      "data_dir : ./cifar10/cifar-10-batches-py\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU()\n",
      "  (7): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): ReLU()\n",
      "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU()\n",
      "  (14): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU()\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (20): ReLU()\n",
      "  (21): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (24): ReLU()\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (27): ReLU()\n",
      "  (28): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (29): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      ")\n",
      "initial weights as normal distribution and bias as zeros\n",
      "[1/8000] train_loss: 0.238  train_accuracy: 0.078 test_accuracy: 0.174\n",
      "[501/8000] train_loss: 0.12  train_accuracy: 0.6416 test_accuracy: 0.651\n",
      "[1001/8000] train_loss: 0.064  train_accuracy: 0.781 test_accuracy: 0.701\n",
      "[1501/8000] train_loss: 0.078  train_accuracy: 0.719 test_accuracy: 0.742\n",
      "[2001/8000] train_loss: 0.077  train_accuracy: 0.752 test_accuracy: 0.764\n",
      "[2501/8000] train_loss: 0.032  train_accuracy: 0.875 test_accuracy: 0.777\n",
      "[3001/8000] train_loss: 0.051  train_accuracy: 0.844 test_accuracy: 0.778\n",
      "[3501/8000] train_loss: 0.028  train_accuracy: 0.922 test_accuracy: 0.782\n",
      "[4001/8000] train_loss: 0.017  train_accuracy: 0.906 test_accuracy: 0.789\n",
      "[4501/8000] train_loss: 0.033  train_accuracy: 0.891 test_accuracy: 0.779\n",
      "[5001/8000] train_loss: 0.017  train_accuracy: 0.938 test_accuracy: 0.793\n",
      "[5501/8000] train_loss: 0.008  train_accuracy: 0.969 test_accuracy: 0.799\n",
      "[6001/8000] train_loss: 0.007  train_accuracy: 0.984 test_accuracy: 0.795\n",
      "[6501/8000] train_loss: 0.007  train_accuracy: 0.969 test_accuracy: 0.794\n",
      "[7001/8000] train_loss: 0.018  train_accuracy: 0.922 test_accuracy: 0.793\n",
      "[7501/8000] train_loss: 0.017  train_accuracy: 0.984 test_accuracy: 0.795\n",
      "[8000/8000] train_loss: 0.009  train_accuracy: 0.969 test_accuracy: 0.797\n"
     ]
    }
   ],
   "source": [
    "!python ./code/train_convnet_pytorch.py --max_steps 8000 --batch_size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "38617826-e431-49fc-bd48-ca6309b30679"
    }
   },
   "outputs": [],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cdc2d048-5b3f-4d70-adec-dc7a2e2b2a30"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_summary_torchconvnet_1573325807.csv\")\n",
    "plt.plot(data[\"step\"], data[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(data[\"step\"], data[\"test_accuracy\"], label=\"test_accuracy\")\n",
    "plt.plot(data[\"step\"], data[\"train_accuracy\"], label=\"train_accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate : 0.0001\n",
      "max_steps : 5000\n",
      "batch_size : 32\n",
      "eval_freq : 500\n",
      "data_dir : ./cifar10/cifar-10-batches-py\n",
      "Traceback (most recent call last):\n",
      "  File \"./code/train_convnet_pytorch_sun.py\", line 197, in <module>\n",
      "    main()\n",
      "  File \"./code/train_convnet_pytorch_sun.py\", line 180, in main\n",
      "    train()\n",
      "  File \"./code/train_convnet_pytorch_sun.py\", line 125, in train\n",
      "    y_pred = model.forward(test_x)\n",
      "  File \"/data/home/wlongxiang/notebooks/DL_assignments_2019/assignment_1/code/convnet_pytorch_sun.py\", line 92, in forward\n",
      "    x = self.cnn_layers(x)\n",
      "  File \"/data/anaconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/data/anaconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/data/anaconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/data/anaconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 343, in forward\n",
      "    return self.conv2d_forward(input, self.weight)\n",
      "  File \"/data/anaconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/conv.py\", line 340, in conv2d_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 2.44 GiB (GPU 0; 15.90 GiB total capacity; 15.04 GiB already allocated; 123.88 MiB free; 76.72 MiB cached)\n"
     ]
    }
   ],
   "source": [
    "!python ./code/train_convnet_pytorch_sun.py --max_steps 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
